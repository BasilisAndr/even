{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling Kamchatka...\n",
      "counting morphemes...\n",
      "counting speakers...\n",
      "counting expected values...\n",
      "counting observed values...\n",
      "counting DP...\n",
      "672\n",
      "[0.009876543209876543, 0, 0.02697841726618705, 0.06779661016949153, 0.08379888268156424, 0.010526315789473684, 0, 0.022222222222222223, 0.0031380753138075313, 0.014459415050936576]\n",
      "293    39\n",
      "42     16\n",
      "287    16\n",
      "114    42\n",
      "358    17\n",
      "Name: count, dtype: int64\n",
      "Kamchatka done\n",
      "handling Sebjan...\n",
      "counting morphemes...\n",
      "counting speakers...\n",
      "counting expected values...\n",
      "counting observed values...\n",
      "counting DP...\n",
      "659\n",
      "[0.014911014911014911, 0, 0.044709388971684055, 0.006544502617801047, 0.003795066413662239, 0, 0.020833333333333332, 0.01060070671378092, 0.012138728323699421, 0.02333931777378815]\n",
      "343    66\n",
      "120    19\n",
      "422    30\n",
      "150    18\n",
      "33     24\n",
      "Name: count, dtype: int64\n",
      "Sebjan done\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MorphemeError(Exception):\n",
    "    '''raised if morpheme is empty'''\n",
    "    def __init__(self, message='Length of lists not equal'):\n",
    "        super(MorphemeError, self).__init__()\n",
    "        self.message = message\n",
    "    def __str__(self):\n",
    "        return repr(self.message)\n",
    "\n",
    "\n",
    "class Morphemes():\n",
    "\n",
    "\n",
    "    def __init__(self, content, corpus):\n",
    "        self.content = content\n",
    "        self.corpus = corpus\n",
    "        self.morphemes = self.morpheme_count()\n",
    "        if '0' in self.morphemes or 0 in self.morphemes:\n",
    "            raise MorphemeError('0 morphemes in morpheme_count')\n",
    "        self.raw_speakers = self.raw_speaker_count()\n",
    "        self.speakers = self.speaker_count() # expected values for DP\n",
    "        self.mbs = self.morpheme_by_speaker_count() # observed values for DP\n",
    "\n",
    "\n",
    "    def morpheme_count(self):\n",
    "        '''returns dict with overall count for morphemes (ignoring speakers)'''\n",
    "        print('counting morphemes...')\n",
    "        items = [x[:3] for x in self.content if x[0][0] in '-=' and not '-ep' in x]\n",
    "        return Counter(items)\n",
    "\n",
    "    \n",
    "    def raw_morpheme_by_speaker_count(self):\n",
    "#     '''generates dict morheme: Counter(by speaker) with number of times speaker said this morpheme'''\n",
    "        alll = {}\n",
    "        for morpheme in self.morphemes:\n",
    "            count = Counter([x[-1] for x in self.content if x[:3]==morpheme])\n",
    "            res = {x: count[x] for x in count}\n",
    "            mor = '-'.join(list(map(lambda x: x.strip('-='), morpheme)))\n",
    "            alll[mor] = res\n",
    "        return alll\n",
    "    \n",
    "    \n",
    "    def morpheme_by_speaker_count(self):\n",
    "        '''generates dict morheme: Counter(by speaker) with proportion of this speaker in the \n",
    "        overall count of this morpheme'''\n",
    "        print('counting observed values...')\n",
    "        alll = {}\n",
    "        for morpheme in self.morphemes:\n",
    "            count = Counter([x[-1] for x in self.content if x[:3]==morpheme])\n",
    "            res = {x: count[x]/self.morphemes[morpheme] for x in count}\n",
    "            mor = '-'.join(list(map(lambda x: x.strip('-='), morpheme)))\n",
    "            alll[morpheme] = res\n",
    "        return alll\n",
    "\n",
    "    def speaker_by_morpheme_count(self):\n",
    "        '''generates dict morpheme: Counter(by speaker) with frequency of this morpheme in this speakers speech'''\n",
    "        alll = {}\n",
    "        for morpheme in self.morphemes:\n",
    "            count = Counter([x[-1] for x in self.content if x[:3]==morpheme])\n",
    "            res = {x: count[x]/self.raw_speakers[x] for x in count}\n",
    "            alll[morpheme] = res\n",
    "        return alll\n",
    "\n",
    "    \n",
    "    def sp_by_pos(self):\n",
    "        '''returns dict speaker: Counter(pos: prop of words with that pos in this speaker's speech)'''\n",
    "        alll = {}\n",
    "        for speaker in self.speakers:\n",
    "            count = Counter([x[-2] for x in self.content if x[-1]==speaker])\n",
    "            res = {x: count[x]/self.raw_speakers[x] for x in count}\n",
    "            alll[speaker] = res\n",
    "        return alll\n",
    "    \n",
    "    \n",
    "    def pos_by_sp(self):\n",
    "        '''returns dict speaker: Counter(pos: prop of this speaker in this pos)'''\n",
    "        alll = {}\n",
    "        poss = Counter([x[-2] for x in self.content])\n",
    "        for pos in poss:\n",
    "            count = Counter([x[-1] for x in self.content if x[-2]==pos])\n",
    "            res = {x: count[x]/poss[pos] for x in count}\n",
    "            alll[pos] = res\n",
    "        return alll\n",
    "    \n",
    "\n",
    "    def calculate_dp(self):\n",
    "        '''well, calculates dp for all morphemes'''\n",
    "        print('counting DP...')\n",
    "        res = {'morpheme': [], 'count': [], 'dp': []}\n",
    "        for sp in self.speakers:\n",
    "            res[sp] = []\n",
    "#         sp_by_mor = self.speaker_by_morpheme_count() # это было нужно для частотностей\n",
    "        for mor in self.mbs:\n",
    "#             sp_count = sp_by_mor[mor]\n",
    "            counts = self.mbs[mor]\n",
    "            res['morpheme'].append('-'.join(list(map(lambda x: x.strip('-='), mor))))\n",
    "            res['count'].append(self.morphemes[mor])\n",
    "            res['dp'].append(dp(self.speakers, counts))\n",
    "            if not sum(counts.values()) > 0.999:\n",
    "                print(mor)\n",
    "                print(self.morphemes[mor])\n",
    "                pprint(counts)\n",
    "                print(sum(counts.values()))\n",
    "                raise MorphemeError('sum not equals 1')\n",
    "            for sp in self.speakers:\n",
    "                if sp in counts:\n",
    "                    res[sp].append(counts[sp])\n",
    "                else:\n",
    "                    res[sp].append(0)\n",
    "        print(len(res['AAS']))\n",
    "        return res\n",
    "\n",
    "\n",
    "    def raw_speaker_count(self):\n",
    "        '''returns dict with the number of words every speaker said in a corpus'''\n",
    "        print('counting speakers...')\n",
    "        items = [x[-1] for x in self.content if x[0]=='END']\n",
    "        return Counter(items)\n",
    "\n",
    "\n",
    "    def speaker_count(self, totals = {'Kamchatka': 33112, 'Sebjan': 49800}):\n",
    "        '''returns dict with proportions of every speaker in a corpus'''\n",
    "        print('counting expected values...')\n",
    "        res = {x: self.raw_speakers[x]/totals[self.corpus] for x in self.raw_speakers}\n",
    "        # pprint(res)\n",
    "        # print(sum(res.values()))\n",
    "        return res\n",
    "\n",
    "\n",
    "def dp(expected, observed):\n",
    "    # step = {sp: expected[sp]-observed[sp] if sp in observed else expected[sp] for sp in expected}\n",
    "    deltas = []\n",
    "    for sp in expected:\n",
    "        if sp in observed:\n",
    "            delta = np.abs(expected[sp]-observed[sp])\n",
    "        else:\n",
    "            delta = 0\n",
    "        deltas.append(delta)\n",
    "    dp = sum(deltas) / 2\n",
    "    return dp\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    corpora = ['Kamchatka', 'Sebjan']\n",
    "    corp_pd = []\n",
    "    for corp in corpora:\n",
    "        print('handling {}...'.format(corp))\n",
    "        with open('../{}_wds_by_mor.pickle'.format(corp), 'rb') as f:\n",
    "            mor = Morphemes(pickle.load(f), corp)\n",
    "        res = mor.calculate_dp()\n",
    "        print(res['AAS'][:10])\n",
    "        columns = ['morpheme', 'count', 'dp'] + sorted(list(mor.speakers.keys()))\n",
    "        a = pd.DataFrame(res).loc[pd.DataFrame(res)['count']>15].sort_values('dp', ascending=False)[columns] \n",
    "        print(a['count'].head())\n",
    "        #.to_excel('{}_dp_new.xlsx'.format(corp))\n",
    "        corp_pd.append(a)\n",
    "        print('{} done'.format(corp))\n",
    "    print('all done')\n",
    "    return corp_pd\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # unittest.main()\n",
    "    a = main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[0]['AAS_k'] = a[0][\"AAS\"]\n",
    "del a[0][\"AAS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надо понять что мне нужно\n",
    "\n",
    "мне нужен\n",
    "\n",
    "- список всех спикеров +\n",
    "- список нужных морфем +\n",
    "\n",
    "надо почистить спикеров по тому, что говорила Бригитта\n",
    "\n",
    "ptc и ptcp не исправлены! аааааа\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morpheme</th>\n",
       "      <th>count</th>\n",
       "      <th>dp</th>\n",
       "      <th>AAS</th>\n",
       "      <th>AEI</th>\n",
       "      <th>AFI</th>\n",
       "      <th>AGK</th>\n",
       "      <th>AL</th>\n",
       "      <th>AMG</th>\n",
       "      <th>AS</th>\n",
       "      <th>...</th>\n",
       "      <th>NFI</th>\n",
       "      <th>NIG</th>\n",
       "      <th>NMK</th>\n",
       "      <th>ONI</th>\n",
       "      <th>PMB</th>\n",
       "      <th>RME</th>\n",
       "      <th>RMS</th>\n",
       "      <th>TEB</th>\n",
       "      <th>VIA</th>\n",
       "      <th>rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>eː-emph-adj</td>\n",
       "      <td>39</td>\n",
       "      <td>0.440800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>WEːČ-gnr.nonfut-v</td>\n",
       "      <td>16</td>\n",
       "      <td>0.430871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>LE-nr-n</td>\n",
       "      <td>16</td>\n",
       "      <td>0.426613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>n-nr-n</td>\n",
       "      <td>42</td>\n",
       "      <td>0.424671</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>El-emph-adv</td>\n",
       "      <td>17</td>\n",
       "      <td>0.416208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              morpheme  count        dp       AAS       AEI  AFI  AGK  AL  \\\n",
       "293        eː-emph-adj     39  0.440800  0.000000  0.102564  0.0  0.0   0   \n",
       "42   WEːČ-gnr.nonfut-v     16  0.430871  0.000000  0.000000  0.0  0.0   0   \n",
       "287            LE-nr-n     16  0.426613  0.000000  0.000000  0.0  0.0   0   \n",
       "114             n-nr-n     42  0.424671  0.071429  0.000000  0.0  0.0   0   \n",
       "358        El-emph-adv     17  0.416208  0.000000  0.000000  0.0  0.0   0   \n",
       "\n",
       "          AMG        AS ...        NFI       NIG      NMK     ONI       PMB  \\\n",
       "293  0.000000  0.025641 ...   0.025641  0.025641  0.00000  0.0000  0.025641   \n",
       "42   0.000000  0.000000 ...   0.000000  0.000000  0.00000  0.0625  0.000000   \n",
       "287  0.062500  0.000000 ...   0.000000  0.562500  0.00000  0.0000  0.062500   \n",
       "114  0.047619  0.047619 ...   0.071429  0.071429  0.02381  0.0000  0.000000   \n",
       "358  0.000000  0.000000 ...   0.117647  0.000000  0.00000  0.0000  0.000000   \n",
       "\n",
       "          RME       RMS  TEB     VIA   rh  \n",
       "293  0.076923  0.025641  0.0  0.0000  0.0  \n",
       "42   0.000000  0.000000  0.0  0.8125  0.0  \n",
       "287  0.062500  0.062500  0.0  0.0000  0.0  \n",
       "114  0.071429  0.142857  0.0  0.0000  0.0  \n",
       "358  0.117647  0.000000  0.0  0.0000  0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "22\n",
      "['(dU)LE-loc-n',\n",
      " '(dU)LE-loc-v',\n",
      " 'DE-purp.cvb-v',\n",
      " 'DU-dat-n',\n",
      " 'R-neg.cvb-v',\n",
      " 'REk-cond.cvb-v',\n",
      " 'RI-impf.ptc-v',\n",
      " 'RIdʒI-ant.cvb-v',\n",
      " 'mI-cond.cvb-v',\n",
      " 'nIkEn-sim.cvb-v',\n",
      " 'skI-advb.all-rel.n',\n",
      " 't(E)kI-all-n',\n",
      " 't(E)kI-all-pron',\n",
      " 'čE-pf.ptc-v']\n"
     ]
    }
   ],
   "source": [
    "# здесь достаются морфемы с которыми работаем\n",
    "n = ['ptc', 'cvb', 'loc', 'dat', 'all']\n",
    "n_0 = [x for x in list(a[0]['morpheme']) if any([y in x for y in n])]\n",
    "n_1 = [x for x in list(a[1]['morpheme']) if any([y in x for y in n])]\n",
    "print(len(n_0))\n",
    "print(len(n_1))\n",
    "needed = sorted(list(set(n_0)&set(n_1)))\n",
    "pprint(needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_speakers = list(a[0].columns[3:])\n",
    "s_speakers = list(a[1].columns[4:])\n",
    "all_speakers = k_speakers + s_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_to_two(A, B):\n",
    "    C = {}\n",
    "    C.update(A)\n",
    "    C.update(B)\n",
    "    res_keys = sorted(C, key=C.get)\n",
    "    res_values = sorted(C.values())\n",
    "    res_A = [res_values[i] if res_keys[i] in A else 0 for i in range(len(res_values))]\n",
    "    res_B = [res_values[i] if res_keys[i] in B else 0 for i in range(len(res_values))]\n",
    "    i = delete_zeros(res_A, res_B)\n",
    "    return res_A[i:], res_B[i:], res_keys[i:]\n",
    "    \n",
    "\n",
    "def delete_zeros(res_A, res_B):\n",
    "    i = 0\n",
    "    while res_A[i] == 0 and res_B[i] == 0:\n",
    "        i+= 1\n",
    "#         print(i)\n",
    "    return i\n",
    "\n",
    "def make_dict(row, speakers):\n",
    "    '''делает словарь спикер: частотность'''\n",
    "    res = {}\n",
    "    for sp in speakers:\n",
    "        try:\n",
    "            res[sp] = row[sp].iloc[0]\n",
    "        except:\n",
    "            print(row)\n",
    "            print(speakers)\n",
    "            raise Exception\n",
    "#             res[sp] = 0\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dp(k_count, s_count):\n",
    "    '''считает дипи для двух корпусов как двух коробок'''\n",
    "    total = k_count + s_count\n",
    "    exp = np.array([33112/(49800+33112), 49800/(49800+33112)])\n",
    "    obs = np.array(k_count/total, s_count/total)\n",
    "    res = np.sum(np.abs(exp-obs))/2\n",
    "    return res\n",
    "\n",
    "from scipy.stats import beta\n",
    "\n",
    "def binom_interval(success, total, confint=0.95):\n",
    "    quantile = (1 - confint) / 2.\n",
    "    lower = beta.ppf(quantile, success, total - success + 1)\n",
    "    upper = beta.ppf(1 - quantile, success + 1, total - success)\n",
    "    return (lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для конфинта нужны\n",
    "\n",
    "- сырые частотности по спикерам (не делённые!)\n",
    "- количество слов по спикерам\n",
    "\n",
    "их надо подготовить (в след. ячейке)\n",
    "\n",
    "считается proportion_confint(raw_count, raw_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora = ['Kamchatka', 'Sebjan']\n",
    "morphemes_cl = []\n",
    "for corp in corpora:\n",
    "    with open('../{}_wds_by_mor.pickle'.format(corp), 'rb') as f:\n",
    "        mor = Morphemes(pickle.load(f), corp)\n",
    "    morphemes_cl.append(mor)\n",
    "    \n",
    "raw_m_k = morphemes_cl[0].raw_morpheme_by_speaker_count()\n",
    "raw_m_s = morphemes_cl[1].raw_morpheme_by_speaker_count()\n",
    "k_raw_speakers = morphemes_cl[0].raw_speaker_count()\n",
    "s_raw_speakers = morphemes_cl[1].raw_speaker_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно конфинты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yerrs(morpheme, res_x):\n",
    "    k_m_by_s = raw_m_k[morpheme]\n",
    "    s_m_by_s = raw_m_s[morpheme]\n",
    "    k_yerr = get_yerr(res_x, k_m_by_s, k_raw_speakers)\n",
    "    s_yerr = get_yerr(res_x, s_m_by_s, s_raw_speakers)\n",
    "    print(res_x)\n",
    "    pprint(len(s_yerr))\n",
    "    for x, y in zip(res_x, k_yerr):\n",
    "        print(x, y)\n",
    "    k_yerr = [[x[0] for x in k_yerr], [x[1] for x in k_yerr]]\n",
    "    s_yerr = [[x[0] for x in s_yerr], [x[1] for x in s_yerr]]\n",
    "    return k_yerr, s_yerr\n",
    "    \n",
    "\n",
    "def get_yerr(order, m_by_s, raw_speakers):\n",
    "    yerr = []\n",
    "    for sp in order:\n",
    "        if sp == \"AAS_k\":\n",
    "            sp = \"AAS\"\n",
    "        if sp in m_by_s:\n",
    "#             if 'AMG' in raw_speakers and sp == 'AAS':\n",
    "#                 print('found')\n",
    "#                 sp = \"AAS\"\n",
    "#                 print(sp)\n",
    "            raw_count = m_by_s[sp]\n",
    "            raw_sp = raw_speakers[sp]\n",
    "            ci = binom_interval(raw_count, raw_sp)\n",
    "            print(sp, ci)\n",
    "            yerr.append(ci)\n",
    "        else:\n",
    "            yerr.append((0, 0))\n",
    "    return yerr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь кусок кода который делает графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting morphemes...\n",
      "counting speakers...\n",
      "counting expected values...\n",
      "counting observed values...\n",
      "counting morphemes...\n",
      "counting speakers...\n",
      "counting expected values...\n",
      "counting observed values...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('-R(E)', '-nonfut', 'v'),\n",
       " ('-RI', '-pst', 'v'),\n",
       " ('-WEːČ', '-gnr', 'v'),\n",
       " ('-W', '-acc', 'n'),\n",
       " ('-n(I)', '-3sg', 'v'),\n",
       " ('-D', '-prog', 'v'),\n",
       " ('-n(I)', '-poss.3sg', 'v'),\n",
       " ('-(dU)LE', '-loc', 'n'),\n",
       " ('-m', '-1sg', 'v'),\n",
       " ('-n(I)', '-poss.3sg', 'n'),\n",
       " ('-L', '-pl', 'n')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp = 'Kamchatka'\n",
    "with open('../{}_wds_by_mor.pickle'.format(corp), 'rb') as f:\n",
    "    kam = Morphemes(pickle.load(f), corp)\n",
    "corp = \"Sebjan\"\n",
    "with open('../{}_wds_by_mor.pickle'.format(corp), 'rb') as f:\n",
    "    seb = Morphemes(pickle.load(f), corp)\n",
    "\n",
    "sorted(kam.morphemes, key=kam.morphemes.get, reverse=True)[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_part = 33112/(49800+33112)\n",
    "s_part = 49800/(49800+33112)\n",
    "k_speakers = kam.speakers.keys()\n",
    "s_speakers = seb.speakers.keys()\n",
    "k_exp = np.array([kam.speakers[x] for x in k_speakers])*k_part\n",
    "s_exp = np.array([seb.speakers[x] for x in s_speakers])*s_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "overall = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969096207188\n",
      "0.02974754112\n",
      "0.319827334093\n",
      "0.507579361256\n",
      "0.321512225153\n",
      "0.168399331695\n",
      "0.0758124137065\n",
      "0.2341946428\n",
      "0.171767980174\n",
      "0.0595081875812\n",
      "0.015585721928\n",
      "0.289246130576\n",
      "0.110633953112\n",
      "0.200578987083\n"
     ]
    }
   ],
   "source": [
    "dps1 = []\n",
    "dps2 = []\n",
    "dpsk = []\n",
    "dpss = []\n",
    "for mor in needed:\n",
    "    row_k = a[0].loc[a[0]['morpheme']==mor]\n",
    "    k = make_dict(row_k, k_speakers)\n",
    "    row_s = a[1].loc[a[1]['morpheme']==mor]\n",
    "    s = make_dict(row_s, s_speakers)\n",
    "    print(sum(k.values()))\n",
    "    dp_1 = calc_dp(row_k['count'].iloc[0], row_s['count'].iloc[0])\n",
    "    k_obs = np.array([kam.mbs[mor][sp] if sp in kam.mbs[mor] else 0 for sp in k_speakers])*k_part\n",
    "    s_obs = np.array([seb.mbs[mor][sp] if sp in seb.mbs[mor] else 0 for sp in s_speakers])*s_part\n",
    "    deltas = np.array([*k_exp, *s_exp])-np.array([*k_obs, *s_obs])\n",
    "    dp_2 = np.sum(np.abs(deltas))/2\n",
    "    dps1.append(dp_1)\n",
    "    dps2.append(dp_2)\n",
    "    dpsk.append(row_k['dp'].iloc[0])\n",
    "    dpss.append(row_s['dp'].iloc[0])\n",
    "#     k = {sp:(kam.speakers[sp]-kam.mbs[mor][sp])*k_part if sp in kam.mbs[mor] else 0 for sp in k_speakers}\n",
    "#     s = {sp:(seb.speakers[sp]-seb.mbs[mor][sp])*s_part if sp in seb.mbs[mor] else 0 for sp in s_speakers}\n",
    "#     # now sort\n",
    "#     res_k, res_s, res_x = sort_to_two(k, s)\n",
    "#     print(set(s_speakers)&set(k_speakers))\n",
    "# #     print(k)\n",
    "#     print(res_s)\n",
    "#     fig, ax = plt.subplots(figsize=(25, 10))\n",
    "#     x = np.arange(len(res_x))\n",
    "# #     yerr = yerrs(mor, res_x)\n",
    "#     plt.xticks(rotation=70)\n",
    "#     ax.bar(x, res_k, color=\"red\")#, yerr=yerr[0])\n",
    "#     ax.bar(x, res_s, color=\"cyan\")#, yerr=yerr[1])\n",
    "#     plt.xticks(x, res_x)\n",
    "# #     dp_k = row_k['dp'].iloc[0]\n",
    "# #     dp_s = row_s['dp'].iloc[0]\n",
    "# #     diff = dp - min(dp_k, dp_s)\n",
    "#     plt.title(\"{}\".format(mor))\n",
    "#     plt.text(0, max(*res_k, *res_s)/2, \"DP:{}\".format(dp))#, \\ndiff: {}, \\nDP K: {}, \\nDP S: {}\".format(dp, diff, dp_k, dp_s))\n",
    "#     plt.legend(['Kamchatka', 'Sebjan'])\n",
    "#     if not os.path.exists(\"pics\"):\n",
    "#         os.mkdir('pics')\n",
    "#     fig.savefig('pics/{}.png'.format(mor))\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"affix\": needed, 'two-part': dps1, 'together': dps2, 'k': dpsk, \"s\": dpss}).to_csv('dps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9690962071879287"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(row_k[row_k.columns[3:]].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morpheme</th>\n",
       "      <th>count</th>\n",
       "      <th>dp</th>\n",
       "      <th>AEI</th>\n",
       "      <th>AFI</th>\n",
       "      <th>AGK</th>\n",
       "      <th>AL</th>\n",
       "      <th>AMG</th>\n",
       "      <th>AS</th>\n",
       "      <th>ASA</th>\n",
       "      <th>...</th>\n",
       "      <th>NIG</th>\n",
       "      <th>NMK</th>\n",
       "      <th>ONI</th>\n",
       "      <th>PMB</th>\n",
       "      <th>RME</th>\n",
       "      <th>RMS</th>\n",
       "      <th>TEB</th>\n",
       "      <th>VIA</th>\n",
       "      <th>rh</th>\n",
       "      <th>AAS_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(dU)LE-loc-n</td>\n",
       "      <td>1044</td>\n",
       "      <td>0.095194</td>\n",
       "      <td>0.022712</td>\n",
       "      <td>0.061947</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.032334</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027682</td>\n",
       "      <td>0.036508</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.02976</td>\n",
       "      <td>0.034907</td>\n",
       "      <td>0.044601</td>\n",
       "      <td>0.028743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        morpheme  count        dp       AEI       AFI       AGK  AL     AMG  \\\n",
       "10  (dU)LE-loc-n   1044  0.095194  0.022712  0.061947  0.031746   0  0.0125   \n",
       "\n",
       "          AS       ASA    ...          NIG       NMK       ONI       PMB  \\\n",
       "10  0.032334  0.014563    ...     0.027682  0.036508  0.073099  0.041359   \n",
       "\n",
       "        RME       RMS       TEB       VIA   rh     AAS_k  \n",
       "10  0.02976  0.034907  0.044601  0.028743  0.0  0.032023  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k_raw_speakers\n",
    "\n",
    "# print(raw_m_k['(dU)LE-loc-n'])\n",
    "# print(raw_m_s['(dU)LE-loc-n'])\n",
    "\n",
    "# morphemes_cl[0].raw_morpheme_by_speaker_count()\n",
    "\n",
    "a[0].loc[a[0]['morpheme']==mor]\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "from scipy import nan\n",
    "\n",
    "\"AMG\" in s_raw_speakers\n",
    "\n",
    "# raw_m_k[\"(dU)LE-loc-n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь мне нужно сделать табличку с десятью самыми частотными морфемами и DP для них.\n",
    "\n",
    "- найти 10 самых частотных +\n",
    "- дропать эпентезы +\n",
    "- написать фц для подсчёта DP по-Даниэлевски\n",
    "- сделать табличку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "нам нужно\n",
    "- ожидаемое значение (self.speaker_count\\*totals/сумму)\n",
    "- наблюдаемое значение (self.morpheme_by_speaker_count\\*то же)\n",
    "\n",
    "вот и всё"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0937218307064\n",
      "0.47713598395\n",
      "0.20117597537\n",
      "0.187034335217\n",
      "0.148158013208\n",
      "0.199633969169\n",
      "0.221812154534\n",
      "0.223476913615\n",
      "0.231593794073\n",
      "0.26031942946\n",
      "0.457502013296\n",
      "0.355641007118\n",
      "0.309329461255\n",
      "0.28635217328\n"
     ]
    }
   ],
   "source": [
    "k_part = 33112/(49800+33112)\n",
    "s_part = 49800/(49800+33112)\n",
    "k_speakers = kam.speakers.keys()\n",
    "s_speakers = seb.speakers.keys()\n",
    "k_exp = np.array([kam.speakers[x] for x in k_speakers])*k_part\n",
    "s_exp = np.array([seb.speakers[x] for x in s_speakers])*s_part\n",
    "\n",
    "for mor in needed:\n",
    "    k_obs = np.array([kam.mbs[mor][sp] if sp in kam.mbs[mor] else 0 for sp in k_speakers])*k_part\n",
    "    s_obs = np.array([seb.mbs[mor][sp] if sp in seb.mbs[mor] else 0 for sp in s_speakers])*s_part\n",
    "    print(np.sum(np.abs(np.array([*k_exp, *s_exp])-np.array([*k_obs, *s_obs])))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1dccabe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([0, 1], [10, 24], color=['red', 'blue'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Spam:\n",
    "    def __new__(self):\n",
    "        self.__init__(self)\n",
    "        print(1)\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(2)\n",
    "\n",
    "class E(Spam):\n",
    "    def __new__(self):\n",
    "        print(3)\n",
    "        \n",
    "    def __init__(self):\n",
    "        print(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.bar(kam, c=\"red\", xticks=)\n",
    "plt.bar(seb, c=\"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
