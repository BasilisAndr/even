{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наброски кода для\n",
    "0. сведения алломорфов морфем в одно (хотя бы в таблице)\n",
    "1. подсчёта сочетаний морфем\n",
    "2. вытаскивания конвербов\n",
    "3. вытаскивания цепочек частей речи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все манипуляции можно тестировать на корпусах, которые в почте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0\n",
    "Действительно надо вытащить всё, положить в словарину и радоваться\n",
    "\n",
    "Формат:\n",
    "\n",
    "`корпус{\n",
    "    название:документ{    # done\n",
    "        мета:мета,    # done\n",
    "        текст:[\n",
    "            предложение{\n",
    "                слой:[\n",
    "                    морфемы\n",
    "                    ],\n",
    "                перевод:''\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora = ['Kamchatka', 'Sebjan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re, pickle\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def morphs_2_words(line):\n",
    "    '''берёт на вход массив расчленённой строки, возвращает массив слов'''\n",
    "    words = []\n",
    "    word = []\n",
    "    for morph in line:\n",
    "        if morph.strip()[0] in '=-':\n",
    "            word.append(morph)\n",
    "        else:\n",
    "            if len(word) > 0:\n",
    "                words.append(word)\n",
    "            word = [morph]\n",
    "    words.append(word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def handle_startline(line, res, current_layer):\n",
    "    line = line.split()\n",
    "    layer = line[0].strip('\\\\')\n",
    "    parted_layers = ['tx', 'mb', 'ge', 'ps']\n",
    "    if not (len(line) == 1): # чтобы не считать пустые строки\n",
    "        if layer in parted_layers:\n",
    "            line_content = morphs_2_words(line[1:]) # делим на слова, состоящие из морфем\n",
    "        else:\n",
    "            line_content = [' '.join(line[1:])] # просто целые строки (комментарии и тп)\n",
    "            current_layer = layer\n",
    "        if layer in res and res[layer][0] != '':\n",
    "            res[layer] += line_content\n",
    "        else:\n",
    "            res[layer] = line_content\n",
    "    return res, current_layer\n",
    "\n",
    "\n",
    "def lines_2_dict(part):\n",
    "    '''\n",
    "    i: кусок текста (предложение) в несколько строк, в каждой строке несколько слоёв, и с другими данными предложения\n",
    "    o: джейсонина вида {'слой': [сл, о, ва], 'слой': содержимое}\n",
    "    доп. ограничения: длина всех строк-массивов равна\n",
    "    '''\n",
    "    res = {}\n",
    "    lines = [line for line in part.split('\\n') if len(line) > 1]\n",
    "    res['index'] = [lines[0].split('_')[-1]]\n",
    "    parted_layers = ['tx', 'mb', 'ge', 'ps']\n",
    "    current_layer = '' # для переносов\n",
    "    for line in lines[1:]:\n",
    "        if line.startswith('\\\\'):\n",
    "            res, current_layer = handle_startline(line, res, current_layer)\n",
    "        else:\n",
    "            if current_layer:\n",
    "                res[current_layer][0] += ' ' + line\n",
    "    return res\n",
    "\n",
    "\n",
    "def check_len(p_sent, fil):\n",
    "    parted_layers = ['mb', 'ge', 'ps']\n",
    "    selected_layers = [key for key in p_sent if key in parted_layers and len(p_sent[key])>1]\n",
    "    # 1. check that the number of words is the same\n",
    "    lengths = set([len(p_sent[key]) for key in selected_layers])\n",
    "    if len(lengths) > 1:\n",
    "        print('Error in {}, here:'.format(fil))\n",
    "        print(lengths)\n",
    "        for l in selected_layers:\n",
    "            print(len(p_sent[l]))\n",
    "            pprint(p_sent[l])\n",
    "        return lengths\n",
    "    # 2. check that morphemes are aligned\n",
    "    if 'mb' in selected_layers and 'ge' in selected_layers:\n",
    "        for i in range(len(p_sent['ge'])):\n",
    "            if len(p_sent['ge'][i]) != len(p_sent['mb'][i]):\n",
    "                print('што-то слиплось в {}'.format(fil))\n",
    "                pprint(p_sent)\n",
    "    return lengths\n",
    "\n",
    "\n",
    "def make_readable(corp):\n",
    "    \"переводит текст корпусов в удобомашиночитаемую джейсонину\"\n",
    "    folder = 'Corpus_Text_{}_postagged'.format(corp)\n",
    "    corpus_dict = {}\n",
    "    for fil in os.listdir(folder):\n",
    "        if 'pyzhik' in fil:\n",
    "            continue\n",
    "        if not fil.endswith('.txt'):\n",
    "            continue\n",
    "        with open(os.path.join(folder, fil), 'r') as f:\n",
    "            text = f.read()\n",
    "        file_content, text_content = {}, []\n",
    "        sents = text.split('\\id')\n",
    "        file_content['meta'] = sents[1] # metainfo at the beginning of the file; not parsed\n",
    "        for sent in sents[2:]:\n",
    "            sent_content = lines_2_dict(sent)\n",
    "            check_len(sent_content, fil)\n",
    "            text_content.append(sent_content)\n",
    "        file_content['text'] = text_content\n",
    "        corpus_dict[fil] = file_content\n",
    "    with open('{}.pickle'.format(corp), 'wb') as f:\n",
    "        pickle.dump(corpus_dict, f)\n",
    "    return corpus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for corp in corpora:\n",
    "    make_readable(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detect(what, where, replace=False, corpora=corpora, show=True):\n",
    "    for corpus in corpora:\n",
    "        hits = []\n",
    "        with open('{}.pickle'.format(corpus), 'rb') as f:\n",
    "            content = pickle.load(f)\n",
    "        for doc in content:\n",
    "            for i in range(len(content[doc]['text'])): # looping through sentences\n",
    "                if not where in content[doc]['text'][i]:\n",
    "                    continue\n",
    "                for word in content[doc]['text'][i][where]:\n",
    "                    if what in word:\n",
    "                        print('Found in {}, {} at {}'.format(corpus, doc, i))\n",
    "                        if show:\n",
    "                            pprint(content[doc]['text'][i])\n",
    "                        hits.append(doc)\n",
    "        if len(hits) == 0:\n",
    "            print('noth found. cool! or not?')\n",
    "        else:\n",
    "            inp = input('correct all these ({} hits) & press Enter and I\\'ll reload.\\n'.format(len(hits)))\n",
    "            if replace:\n",
    "                target = replace\n",
    "                for doc in list(set(hits)):\n",
    "                    with open(os.path.join('Corpus_Text_{}_postagged'.format(corpus), doc), 'r') as f:\n",
    "                        text = f.read()\n",
    "                    a_hits = re.findall('{}\\\\b'.format(what), text)\n",
    "                    while len(a_hits) > len(hits):\n",
    "                        print('what is not accurate. see what\\'d be affected')\n",
    "                        pprint(a_hits[:15])\n",
    "                        what = input('change the what: ')\n",
    "                        a_hits = re.findall('{} '.format(what.replace('.', '\\.')), text)\n",
    "                    text = re.sub('{}(\\\\b)'.format(what.replace('.', '\\.')), '{}\\\\1'.format(target), text)\n",
    "                    with open(os.path.join('Corpus_Text_{}_postagged'.format(corpus), doc), 'w') as f:\n",
    "                        f.write(text)\n",
    "            make_readable(corpus)\n",
    "            print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in Kamchatka, Egorova_RM_Tvajan.txt at 23\n",
      "Found in Kamchatka, Egorova_RM_Tvajan.txt at 29\n",
      "Found in Kamchatka, Egorova_RM_Tvajan.txt at 37\n",
      "Found in Kamchatka, Amganov_EI_pear_story.txt at 11\n",
      "Found in Kamchatka, Ichanga_AF_pear_story.txt at 14\n",
      "Found in Kamchatka, Egorova_RM_Yakutia.txt at 0\n",
      "Found in Kamchatka, Egorova_RM_Yakutia.txt at 39\n",
      "Found in Kamchatka, Egorova_RM_Yakutia.txt at 42\n",
      "Found in Kamchatka, Egorova_RM_Yakutia.txt at 81\n",
      "Found in Kamchatka, Egorova_RM_Yakutia.txt at 91\n",
      "Found in Kamchatka, Egorova_RM_Yakutia.txt at 97\n",
      "Found in Kamchatka, Indanova_ON_Moscow.txt at 12\n",
      "Found in Kamchatka, Axmetova_VI_childhood.txt at 1\n",
      "Found in Kamchatka, Axmetova_VI_childhood.txt at 19\n",
      "Found in Kamchatka, Indanova_ON_tabun.txt at 4\n",
      "Found in Kamchatka, Ichanga_Adukanov_museum.txt at 19\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 2\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 3\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 5\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 8\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 11\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 12\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 13\n",
      "Found in Kamchatka, Amganovy_rybalka_tabun.txt at 17\n",
      "Found in Kamchatka, Axmetova_VI_tabun.txt at 5\n",
      "Found in Kamchatka, Axmetova_VI_tabun.txt at 40\n",
      "Found in Kamchatka, Axmetova_VI_tabun.txt at 42\n",
      "Found in Kamchatka, Amganovy_family.txt at 14\n",
      "Found in Kamchatka, Amganovy_family.txt at 21\n",
      "Found in Kamchatka, Solodikova_RM_pear_story.txt at 0\n",
      "Found in Kamchatka, Axmetova_VI_oxrannik_olenej.txt at 5\n",
      "Found in Kamchatka, Amganovy_historical.txt at 5\n",
      "Found in Kamchatka, Amganovy_historical.txt at 9\n",
      "Found in Kamchatka, Amganovy_historical.txt at 12\n",
      "Found in Kamchatka, Amganovy_historical.txt at 16\n",
      "correct all these (35 hits) & press Enter and I'll reload.\n",
      "\n",
      "Error in Amganovy_family.txt, here:\n",
      "{4, 5}\n",
      "4\n",
      "[['stockpile.fish', '-prog', '-nonfut'],\n",
      " ['what', '-dat'],\n",
      " ['fishing.camp.R', '-loc'],\n",
      " ['stockpile.fish', '-prog', '-nonfut']]\n",
      "5\n",
      "[['teli', '-D', '-R(E)'],\n",
      " ['ịak', '-DU'],\n",
      " ['rybalka', '-(dU)LE'],\n",
      " ['teli', '-D', '-R(E)'],\n",
      " ['nọŋartan']]\n",
      "5\n",
      "[['v'], ['pron'], ['n'], ['v'], ['pron']]\n",
      "Error in Amganovy_family.txt, here:\n",
      "{12, 13}\n",
      "12\n",
      "[['which', '-loc', '=emph'],\n",
      " ['domestic.reindeer', '-agnr', '-pl'],\n",
      " ['base.R', '-loc', '-poss.3pl'],\n",
      " ['be', '-prog', '-nonfut', '-ep', '-3sg'],\n",
      " ['also.R'],\n",
      " ['child', '-aln', '-ep', '-pl', '-com', '-prfl.sg'],\n",
      " ['dist', '-dat'],\n",
      " ['dist', '-dat'],\n",
      " ['work', '-prog', '-gnr', '-nonfut'],\n",
      " ['***'],\n",
      " ['guard.R', '-ep', '-prog', '-gnr', '-nonfut'],\n",
      " ['what', '=indef', '-ep', '=emph']]\n",
      "13\n",
      "[['irek', '-(dU)LE', '=kE'],\n",
      " ['ọrọn', '-mŋE', '-L'],\n",
      " ['baza', '-(dU)LE', '-tEn'],\n",
      " ['bi', '-D', '-R(E)', '-E', '-n(I)'],\n",
      " ['tože'],\n",
      " ['kụŋa', '-ŋ', '-E', '-L', '-ńUn', '-J'],\n",
      " ['tarak', '-DU'],\n",
      " ['tarak', '-DU'],\n",
      " ['gurgeːwči', '-D', '-WEːČ', '-R(E)'],\n",
      " ['nọŋartan'],\n",
      " ['*sto'],\n",
      " ['starožit', '-E', '-D', '-WEːČ', '-R(E)'],\n",
      " ['ịak', '=(W)UttE', '-E', '=sI']]\n",
      "13\n",
      "[['pron'],\n",
      " ['n'],\n",
      " ['n'],\n",
      " ['v'],\n",
      " ['ptl'],\n",
      " ['n'],\n",
      " ['pron'],\n",
      " ['pron'],\n",
      " ['v'],\n",
      " ['pron'],\n",
      " ['?'],\n",
      " ['v'],\n",
      " ['pron']]\n",
      "Error in Amganovy_historical.txt, here:\n",
      "{8, 7}\n",
      "7\n",
      "[['reindeer.herding.Koryak', '-vr', '-gnr', '-nonfut'],\n",
      " ['because.R'],\n",
      " ['3pl'],\n",
      " ['together'],\n",
      " ['grow', '-pst', '-poss.3pl'],\n",
      " ['therefore', '=ptl'],\n",
      " ['speak', '-gnr', '-nonfut']]\n",
      "8\n",
      "[['čajčaba', '-DI', '-WEːČ', '-R(E)'],\n",
      " ['nọŋartan'],\n",
      " ['potomučto'],\n",
      " ['nọŋartan'],\n",
      " ['omettu'],\n",
      " ['isu', '-RI', '-tEn'],\n",
      " ['teːmi', '=DE'],\n",
      " ['tore', '-WEːČ', '-R(E)']]\n",
      "8\n",
      "[['v'], ['pron'], ['conj'], ['pron'], ['adv'], ['v'], ['conj'], ['v']]\n",
      "Error in Egorova_RM_Yakutia.txt, here:\n",
      "{10, 11}\n",
      "10\n",
      "[['various', '-ins'],\n",
      " ['3pl'],\n",
      " ['1pl.in', '-pred.poss'],\n",
      " ['child', '-pl'],\n",
      " ['do', '-ep', '-prog', '-cond.cvb'],\n",
      " ['what', '-acc', '=indef?'],\n",
      " ['domestic.reindeer', '-acc'],\n",
      " ['see', '-caus', '-res', '-gnr', '-nonfut'],\n",
      " ['ptl.R'],\n",
      " ['horse', '-acc']]\n",
      "11\n",
      "[['gịakị', '-Č'],\n",
      " ['nọŋartan'],\n",
      " ['mut', '-ŋI'],\n",
      " ['kụŋa', '-L'],\n",
      " ['uŋ', '-E', '-D', '-mI'],\n",
      " ['ịak', '-W', '=dak'],\n",
      " ['ọrọn', '-W'],\n",
      " ['it', '-WkEn', '-Č', '-WEːČ', '-R(E)'],\n",
      " ['nọŋartan'],\n",
      " ['že'],\n",
      " ['mụran', '-W']]\n",
      "11\n",
      "[['pron'],\n",
      " ['pron'],\n",
      " ['pron'],\n",
      " ['n'],\n",
      " ['v'],\n",
      " ['pron'],\n",
      " ['n'],\n",
      " ['v'],\n",
      " ['pron'],\n",
      " ['ptl'],\n",
      " ['n']]\n",
      "Error in Egorova_RM_Yakutia.txt, here:\n",
      "{5, 6}\n",
      "5\n",
      "[['say', '-pst', '-poss.3sg'],\n",
      " ['dist', '-nonfut', '-ep', '=emph'],\n",
      " ['say.nonfut', '-3sg'],\n",
      " ['get.mixed.up', '-res', '-nonfut'],\n",
      " ['Yukaghir', '-ep', '-pl', '-com']]\n",
      "6\n",
      "[['goːn', '-RI', '-n(I)'],\n",
      " ['tarak', '-R(E)'],\n",
      " ['nọŋartan', '-E', '=sI'],\n",
      " ['goːn', '-n(I)'],\n",
      " ['amụ', '-Č', '-R(E)'],\n",
      " ['jukagir', '-E', '-L', '-ńUn']]\n",
      "6\n",
      "[['v'], ['v'], ['pron'], ['?'], ['v'], ['n']]\n",
      "done!\n",
      "Found in Sebjan, Stepanova_ZA_3_hunting_stado.txt at 8\n",
      "Found in Sebjan, Stepanov_AA_elk.txt at 12\n",
      "Found in Sebjan, Krivoshapkina_AE_childhood.txt at 58\n",
      "Found in Sebjan, Krivoshapkina_AE_childhood.txt at 63\n",
      "Found in Sebjan, Krivoshapkina_AE_childhood.txt at 64\n",
      "Found in Sebjan, Stepanova_ZA_1_svatovstvo.txt at 32\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 18\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 19\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 20\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 51\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 52\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 52\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 53\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 58\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 62\n",
      "Found in Sebjan, Zavarov_VN_poselok.txt at 53\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 3\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 31\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 52\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 56\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 69\n",
      "Found in Sebjan, Nikitin_Mitja_pearstory.txt at 9\n",
      "Found in Sebjan, Nikitin_Mitja_pearstory.txt at 10\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 1\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 2\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 4\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 7\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 9\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 37\n",
      "Found in Sebjan, Zaxarova_JP_pear_story.txt at 16\n",
      "Found in Sebjan, Zaxarova_JP_pear_story.txt at 16\n",
      "Found in Sebjan, Zaxarova_JP_pear_story.txt at 17\n",
      "Found in Sebjan, Zaxarova_JP_pear_story.txt at 17\n",
      "Found in Sebjan, Krivoshapkina_Sofija_life.txt at 37\n",
      "Found in Sebjan, Krivoshapkina_Sofija_life.txt at 60\n",
      "Found in Sebjan, Krivoshapkina_Sofija_life.txt at 65\n",
      "Found in Sebjan, Kejmetinova_AA_headmistress_Yakutsk_310310_LZ.txt at 69\n",
      "Found in Sebjan, Kejmetinova_AA_headmistress_Yakutsk_310310_LZ.txt at 75\n",
      "Found in Sebjan, Krivoshapkin_DM_Segen.txt at 0\n",
      "Found in Sebjan, Krivoshapkin_DM_Segen.txt at 28\n",
      "Found in Sebjan, Krivoshapkin_DM_Segen.txt at 31\n",
      "Found in Sebjan, Krivoshapkin_DM_Segen.txt at 36\n",
      "Found in Sebjan, Krivoshapkin_DM_Segen.txt at 43\n",
      "Found in Sebjan, Stepanov_AA_his_life.txt at 17\n",
      "Found in Sebjan, Stepanov_AA_his_life.txt at 17\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 15\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 15\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 17\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 18\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 21\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 24\n",
      "correct all these (51 hits) & press Enter and I'll reload.\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "detect('-nonfut.3pl', 'ge', replace='-nonfut', show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noth found. cool! or not?\n",
      "noth found. cool! or not?\n",
      "noth found. cool! or not?\n",
      "noth found. cool! or not?\n",
      "noth found. cool! or not?\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 3\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 56\n",
      "Found in Sebjan, Krivoshapkina_Marta_bear.txt at 69\n",
      "Found in Sebjan, Stepanov_AA_his_life.txt at 17\n",
      "Found in Sebjan, Krivoshapkina_AE_childhood.txt at 63\n",
      "Found in Sebjan, Krivoshapkina_AE_childhood.txt at 64\n",
      "Found in Sebjan, Stepanova_ZA_1_svatovstvo.txt at 32\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 18\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 52\n",
      "Found in Sebjan, Kejmetinova_TV_pear_story_new.txt at 58\n",
      "Found in Sebjan, Kejmetinova_AA_headmistress_Yakutsk_310310_LZ.txt at 69\n",
      "Found in Sebjan, Nikitin_Mitja_pearstory.txt at 9\n",
      "Found in Sebjan, Nikitin_Mitja_pearstory.txt at 10\n",
      "Found in Sebjan, Zavarov_VN_poselok.txt at 53\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 2\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 7\n",
      "Found in Sebjan, SlepcovaNA_her_class.txt at 9\n",
      "Found in Sebjan, Krivoshapkina_Sofija_life.txt at 60\n",
      "Found in Sebjan, Krivoshapkina_Sofija_life.txt at 65\n",
      "Found in Sebjan, Krivoshapkin_DM_Segen.txt at 43\n",
      "Found in Sebjan, Zaxarova_JP_pear_story.txt at 17\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 15\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 17\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 18\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 21\n",
      "Found in Sebjan, Krivoshapkin_IN_pearstory_new.txt at 24\n",
      "correct all these (26 hits) & press Enter and I'll reload.\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for nf in ['-nonfut3pl', '-nonfut3sg', '-nonfut.3pl']:\n",
    "    detect(nf, 'ge', replace='-nonfut', show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axmetova_VI_pyzhik_LZ.txt\n",
      "Axmetova_VI_pyzhik_LZ_RM.txt\n",
      "done\n",
      "Kejmetinova_AA_headmistress_Yakutsk_310310_LZ.txt\n",
      "Kejmetinova_TV_pear_story_new.txt\n",
      "Krivoshapkin_DM_Segen.txt\n",
      "Krivoshapkin_IN_pearstory_new.txt\n",
      "Krivoshapkina_AE_childhood.txt\n",
      "Krivoshapkina_Marta_bear.txt\n",
      "Krivoshapkina_Sofija_life.txt\n",
      "Nikitin_Mitja_pearstory.txt\n",
      "SlepcovaNA_her_class.txt\n",
      "Stepanov_AA_his_life.txt\n",
      "Stepanova_ZA_1_svatovstvo.txt\n",
      "Zavarov_VN_poselok.txt\n",
      "Zaxarova_JP_pear_story.txt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "token = '-nonfut.3pl'\n",
    "for corp in corpora:\n",
    "    folder = 'Corpus_Text_{}_postagged'.format(corp)\n",
    "    for fil in os.listdir(folder):\n",
    "        with open(os.path.join(folder, fil)) as f:\n",
    "            text = f.read()\n",
    "        if token in text:\n",
    "            print(fil)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pprint(content['Alekseeva_RD_lost_tapes_znatoki_NA.txt']['text'][55]['ge'])\n",
    "fil = 'Kejmetinova_AA_headmistress_Yakutsk_310310_LZ.txt'\n",
    "with open(os.path.join('Corpus_Text_Sebjan_postagged', fil), 'r') as f:\n",
    "    text = f.read()\n",
    "sents = text.split('\\id')\n",
    "for i in range(len(sents)):\n",
    "    sent_content = lines_2_dict(sents[i])\n",
    "    check_len(sent_content, fil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "это уже начато там\n",
    "морфемы лежат в отдельном словаре, кажется; нужно приложить это знание на таблицу?\n",
    "или создать уже наконец промежуточное представление всего"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "сочетания морфем\n",
    "\n",
    "сначала надо вытащить представления (кажется это уже сделано)\n",
    "\n",
    "пройтись по всему, растащить каждое слово на пары морфем, первая (ROOT, morph), последняя (morph, END)\n",
    "\n",
    "`from collections import Counter\n",
    "# вытаскиваю все морфемы из первого слота, считаю, с чем они сочитаются, записываю в словарь\n",
    "morph_pairs_dict = {x: Counter([pair for pair in morph_pairs_list if pair[0]==x]) for x in set(map(lambda pair: pair[0], morph_pairs_list))}\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
